{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1brNtQIjfZOHKuNupvMwNkqYxkFR7h6wB","authorship_tag":"ABX9TyOKh1BEHzMv+LCgghEcz7oe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Author : Rahul Bhoyar\n","\n"],"metadata":{"id":"gEvjRW5hhmY7"}},{"cell_type":"markdown","source":["In this tutorial, we will demonstrate the process of compiling data from a CSV file and organizing it into a structured PDF document. The resulting PDF will serve as our \"Knowledge-Base,\" supporting the implementation of the RAG (Retrieval Augmented Generation) technique. This procedure aims to provide a comprehensive resource for effectively utilizing the RAG model for various applications."],"metadata":{"id":"9G0qkKSWhqdf"}},{"cell_type":"markdown","source":["Installing the necessary libraries"],"metadata":{"id":"I1iXnjXliSxP"}},{"cell_type":"code","source":["!pip install reportlab"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P8cGyZf4lkVw","executionInfo":{"status":"ok","timestamp":1708554922904,"user_tz":-60,"elapsed":11357,"user":{"displayName":"Rahul Bhoyar","userId":"03458412160178633274"}},"outputId":"76655d76-837c-4477-81dc-e22d47be5973"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: reportlab in /usr/local/lib/python3.10/dist-packages (4.1.0)\n","Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from reportlab) (9.4.0)\n","Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from reportlab) (5.2.0)\n"]}]},{"cell_type":"markdown","source":["Code to create a PDF file."],"metadata":{"id":"BwT3vwDsiXn7"}},{"cell_type":"code","source":["import pandas as pd\n","from reportlab.pdfgen import canvas\n","from tqdm import tqdm\n","\n","def create_pdf(csv_file, pdf_file):\n","    # Read CSV data into a pandas DataFrame\n","    df = pd.read_csv(csv_file)\n","\n","    # Create a PDF document\n","    pdf = canvas.Canvas(pdf_file)\n","\n","    # Set font for the content\n","    pdf.setFont(\"Helvetica\", 12)\n","\n","    # Set consistent margins\n","    top_margin = 750\n","    bottom_margin = 50\n","    left_margin = 100\n","    right_margin = 500\n","\n","    # Function to wrap text based on available space\n","    def wrap_text(text, available_space):\n","        words = text.split()\n","        lines = []\n","        current_line = words[0]\n","\n","        for word in words[1:]:\n","            if pdf.stringWidth(current_line + \" \" + word, \"Helvetica\", 12) < available_space:\n","                current_line += \" \" + word\n","            else:\n","                lines.append(current_line)\n","                current_line = word\n","\n","        lines.append(current_line)\n","        return lines\n","\n","    # Write data to the PDF for each row\n","    for index, row in tqdm(df.iterrows()):\n","        # Calculate available space on the current page\n","        available_space = top_margin - bottom_margin\n","\n","        if available_space < 50:  # Check if there's enough space on the current page\n","            pdf.showPage()  # Create a new page\n","            top_margin = 750  # Reset top margin for the new page\n","\n","            # Set font for the rest of the content on subsequent pages\n","            pdf.setFont(\"Helvetica\", 12)\n","\n","        # Write data to the PDF for each column in the row\n","        for col in df.columns:\n","            text = f\"{col}: {row[col]}\"\n","            lines = wrap_text(text, right_margin - left_margin)\n","\n","            for line in lines:\n","                pdf.drawString(left_margin, top_margin, line)\n","                top_margin -= 15  # Adjust Y position for the next line\n","\n","        # Draw separator line after each row\n","        pdf.line(left_margin, top_margin, right_margin, top_margin)\n","        top_margin -= 20  # Add extra space between rows\n","\n","    # Save the PDF outside the loop, after all rows have been processed\n","    pdf.save()\n"],"metadata":{"id":"WCvuzRy52mmE","executionInfo":{"status":"ok","timestamp":1708555748069,"user_tz":-60,"elapsed":4,"user":{"displayName":"Rahul Bhoyar","userId":"03458412160178633274"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["CSV_FILE_PATH = \"kaggle_datasets_v4.csv\""],"metadata":{"id":"RqPzS78C0wm9","executionInfo":{"status":"ok","timestamp":1708555750877,"user_tz":-60,"elapsed":453,"user":{"displayName":"Rahul Bhoyar","userId":"03458412160178633274"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["pdf_file_path = \"knowlege_base_kaggle_datasets.pdf\"  # Replace with your desired PDF output path\n","\n","create_pdf(CSV_FILE_PATH, pdf_file_path)\n","print(\"File saved.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1fz7r3DvlkQN","executionInfo":{"status":"ok","timestamp":1708555756877,"user_tz":-60,"elapsed":3953,"user":{"displayName":"Rahul Bhoyar","userId":"03458412160178633274"}},"outputId":"0dd91dfb-3d0c-4e28-fa87-44652f36310b"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["2155it [00:03, 689.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["File saved.\n"]}]},{"cell_type":"markdown","source":["Querying"],"metadata":{"id":"2FB2yS0yzK3N"}},{"cell_type":"code","source":["pip install langchain_openai"],"metadata":{"id":"3pWRJYTL1v3i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","\n","llm = ChatOpenAI()"],"metadata":{"id":"ql8wu-96aLz2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.chains import ConversationalRetrievalChain\n","\n","chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=new_db2.as_retriever())\n"],"metadata":{"id":"32XlHSvPI3nd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Querying"],"metadata":{"id":"n0aTcpRZaNry"}},{"cell_type":"code","source":["query = \"\"\"\n","\n","Give me the dataset for Energy Consumption. I want at least 10 datasets.\n","Format should be :\n","Sr No -\n","Dataset name -\n","URL -\n","\n","\"\"\""],"metadata":{"id":"xKVkYY8ZI7Zf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CHAT_HISTORY = []\n","\n","\n","result = chain({\"question\": query,\"chat_history\" : CHAT_HISTORY})"],"metadata":{"id":"xjEuDCNpI9Zi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result['answer']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"Qi-3SDr3I_vi","executionInfo":{"status":"ok","timestamp":1708282518518,"user_tz":-60,"elapsed":5,"user":{"displayName":"Rahul Bhoyar","userId":"03458412160178633274"}},"outputId":"6f523e64-4ebb-47f2-f2a1-43c2267c37ca"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"I found a dataset related to energy prediction that you might find interesting:\\n\\n1. Dataset name: Appliances energy prediction\\n   URL: https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction\\n\\nUnfortunately, I couldn't find 10 datasets specifically related to energy consumption.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":109}]},{"cell_type":"code","source":["1\n","Cardiovascular Disease Dataset\n","https://github.com/durgeshrao9993/heart-failure-dataset\n","\n","2\n","A-Z Medicine Dataset of India\n","https://github.com/shudhanshusingh/az-medicine-dataset-of-india"],"metadata":{"id":"4kRmEWVTKY2V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["1 - Electoral Datasets - https://www.kaggle.com/datasets/arnabmitra007/electoral-datasets\n","2 - polityafter91 - https://www.kaggle.com/datasets/prakharatre99/polityafter91\n","3 - Bangladesh's 2024 Election News Dataset - https://www.kaggle.com/datasets/mahinshikder/polotical"],"metadata":{"id":"a0Lycp_1Ybfm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["1. Malicious URLs dataset\n","   URL: sid321axn/malicious-urls-dataset\n","\n","2. WEB-D-E\n","   URL: saurabhshahane/webdemon\n","\n","3. Earthquake dataset\n","   URL: warcoder/earthquake-dataset"],"metadata":{"id":"j13ll6cefYg3"},"execution_count":null,"outputs":[]}]}